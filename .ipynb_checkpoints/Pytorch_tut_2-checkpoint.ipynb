{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.Tensor([5,3])\n",
    "y = torch.Tensor([3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15., 12.])\n"
     ]
    }
   ],
   "source": [
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.zeros([2,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand([2,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3996, 0.0335, 0.8959, 0.3686, 0.5969],\n",
       "        [0.1446, 0.0367, 0.4110, 0.9466, 0.3426]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in torch reshape is view\n",
    "y = y.view([1,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3996, 0.0335, 0.8959, 0.3686, 0.5969, 0.1446, 0.0367, 0.4110, 0.9466,\n",
       "         0.3426]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision \n",
    "from torchvision import transforms,datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\",train=True,download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor()])) \n",
    "\n",
    "\n",
    "test = datasets.MNIST(\"\",train=False,download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor()])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train,\n",
    "                                       batch_size=10,\n",
    "                                      shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test,\n",
    "                                       batch_size=10,\n",
    "                                      shuffle=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([4, 4, 4, 0, 8, 6, 6, 6, 9, 6])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "x,y = data[0][0],data[1][0]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[0][0].view(28,28))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "total = 0 \n",
    "counter_dict = {0:0,1:0,2:0,3:0,4:0,\n",
    "               5:0,6:0,7:0,8:0,9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs,Ys = data \n",
    "    for y in Ys:\n",
    "        counter_dict[int(y)]+=1\n",
    "        total+=1\n",
    "        \n",
    "print(counter_dict)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784,64) #64 is random\n",
    "        self.fc2 = nn.Linear(64,64)\n",
    "        self.fc3 = nn.Linear(64,64)\n",
    "        self.fc4 = nn.Linear(64,10) #10 class\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x,dim=1)  \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "net = Net()     \n",
    "print(net) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((28,28))\n",
    "x = x.view(-1,28*28)  # -1 and 1 to prepare for it any size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2730, -2.3274, -2.2398, -2.3974, -2.3581, -2.1563, -2.3178, -2.2411,\n",
       "         -2.3822, -2.3592]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0898, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim \n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001)\n",
    "EPOCHS = 3 \n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        X ,y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1,28*28))\n",
    "        loss = F.nll_loss(output,y)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "    print(loss)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY 0.98\n"
     ]
    }
   ],
   "source": [
    "correct = 0 \n",
    "total = 0 \n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X,y = data \n",
    "        output = net(X.view(-1,784))\n",
    "        for idx,i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct+=1\n",
    "                \n",
    "            total+=1\n",
    "            \n",
    "print(\"ACCURACY\",round(correct/total,3))            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[1].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[1].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
